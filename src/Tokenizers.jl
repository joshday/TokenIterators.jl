module Tokenizers

using StyledStrings, StringViews

import Base: startswith, findfirst, findnext, /, tail

export Token, State,
    JSONTokens, HTMLTokens, XMLTokens,
    Before, Not, First, Last, â‰º, Â¬, â†, â†’, â‹†, â‰›, â‰ª, ğ‘ ,
    next, is, isfirst, _findnext

#-----------------------------------------------------------------------------# utils
const Data = AbstractVector{UInt8}
const SData = AbstractString


#-----------------------------------------------------------------------------# Selectors
for (Sel, sym) in (:Before => :â‰º, :First => :â†, :Last => :â†’, :Not => :Â¬, :UseStringView => :ğ‘ )
    @eval (struct $Sel{T} x::T end; $sym(x) = $Sel(x))
end

# A selector `x` must satisfy: if `isfirst(x, data) == true` then `first(_findnext(x, data, 1)) == 1`

@inline â‰ª(a, b) = isfirst(a, b)

@inline is(a) = Base.Fix1(is, a)
@inline is(f::Function) = f

@inline is(a::T, b::T) where {T} = a == b
@inline is(a::Char, b::UInt8) = UInt8(a) == b
@inline is(a::UInt8, b::Char) = Char(a) == b
@inline is(f::Function, b) = f(b)
@inline is(n::Not, b) = !is(n.x, b)

# Fallback methods
@inline isfirst(x, d) = is(x, first(d))
@inline isfirst(o::UseStringView, d) = isfirst(o.x, StringView(d))
@inline _findnext(arg, data, i) = findnext(is(arg), data, i)
@inline _findnext(o::UseStringView, data, i) = findnext(is(o.x), StringView(data), i)

@inline isfirst(x::AbstractVector, d) = all(is(x)(d) for (x,d) in zip(x,d))
@inline _findnext(x::AbstractVector, d, i) = findnext(x, d, i)

@inline isfirst(t::Tuple, d) = isempty(t) ? true : is(t[1], d[1]) && isfirst(tail(t), @view(d[2:end]))
@inline _findnext(t::Tuple, d, i) = (j = _findnext(t[1], d,i); isfirst(t, @view(d[j:end])) ? j + length(t) - 1 : _findnext(t, d, j + 1))

# Selectors that only work with _findnext
@inline _findnext(j::Int, d, i) = j
@inline _findnext(f::First, d, i) = (rng = _findnext(f.x, d, i); isnothing(rng) ? nothing : first(rng))
@inline _findnext(f::Last, d, i) =  (rng = _findnext(f.x, d, i); isnothing(rng) ? nothing : last(rng))
@inline _findnext(b::Before, d, i) = (j = _findnext(b.x, d, i); isnothing(j) ? length(d) : j - 1)


#-----------------------------------------------------------------------------# State
struct State{T} x::T end
State(; kw...) = State(NamedTuple(kw))
(o::State{T})(state) where {T} = o.x
(o::State{<:Function})(state) = o.x(state)
(o::State{<:NamedTuple})(state) = merge(state, o.x)


#-----------------------------------------------------------------------------# Token
struct Token{T <: Data, K, S} <: Data
    data::T
    kind::K
    i::Int
    j::Int
    state::S
end
Token(data, kind, state=nothing) = Token(data, kind, 1, 0, state)

â‹†(t::Token{T,K,S}, k::K) where {T,K,S} = Token(t.data, k, t.i, t.j, t.state)
â‰›(t::Token{T,K,S}, k::K) where {T,K,S} = Token(t.data, k, t.i, t.i, t.state)
â‹†(t::Token{T,K,S}, s::State) where {T,K,S} = Token(t.data, t.kind, t.i, t.j, s(t.state))
â‹†(t::Token{T,K,S}, x) where {T,K,S} = Token(t.data, t.kind, t.i, t.i - 1 + _findnext(x, t, 2), t.state)
# â‰€(t::Token{T,K,S}, x) where {T,K,S} = Token(t.data, t.kind, t.i, t.i - 1 + _findnext(x, StringView(t), 2), t.state)

Base.view(t::Token) = view(t.data, t.i:t.j)
StringViews.StringView(t::Token) = StringView(view(t))
Base.length(t::Token) = t.j - t.i + 1
Base.size(t::Token) = (length(t),)
Base.getindex(t::Token, i::Integer) = getindex(view(t), i)
function Base.show(io::IO, ::MIME"text/plain", t::Token)
    format(x::Int) = replace(string(x), r"(\d)(?=(\d{3})+(?!\d))" => s"\1_")
    rng = styled"{bright_black:$(format(t.i)):$(format(t.j)) len=$(format(length(t)))}"
    s = styled"$rng {bright_cyan:$(t.kind)} "
    n = displaysize(io)[2] - length(s) - 1
    _s2 = styled"{inverse:{bright_cyan:$(escape_string(StringView(t)))}}"
    s2 = _s2[1:min(n, end)] * (length(_s2) > n ? styled"{bright_cyan:â€¦}" : "")
    print(io, s, s2)
end
Base.show(io::IO, t::Token) = show(io, MIME("text/plain"), t)

after(t::Token) = Token(t.data, t.kind, t.j + 1, length(t.data), t.state)




#-----------------------------------------------------------------------------# Tokenizer
abstract type Tokenizer{T, K, S} end
Base.IteratorSize(::Type{T}) where {T <: Tokenizer} = Base.SizeUnknown()
Base.eltype(::Type{Tok}) where {T, K, S, Tok <: Tokenizer{T, K, S}} = Token{T, K}
Base.isdone(o::Tokenizer, n::Token) = isempty(n)
Base.show(io::IO, o::Tokenizer) = print(io, typeof(o).name.name, " ($(summary(o.data)))")

init(::Type{Symbol}) = :init
init(::Type{Bool}) = false
init(::Type{Nothing}) = nothing
init(::Type{Vector{T}}) where {T} = T[]
init(::Type{Set{T}}) where {T} = Set{T}()
init(::Type{NT}) where {NT <: NamedTuple} = NT(init.(NT.types))

init(t::Tokenizer{T,K,S}) where {T,K,S} = Token(t.data, init(K), 1, length(t.data), init(S))

function Base.iterate(o::Tokenizer, n = init(o))
    Base.isdone(o, n) && return nothing
    n = next(o, n)
    return n, after(n)
end


#-----------------------------------------------------------------------------# JSONTokens
struct JSONTokens{T <: Data} <: Tokenizer{T, Symbol, Nothing}
    data::T
end
function next(o::JSONTokens, n::Token)
    '{' â‰ª n && return n â‰› :curly_open
    '}' â‰ª n && return n â‰› :curly_close
    '[' â‰ª n && return n â‰› :square_open
    ']' â‰ª n && return n â‰› :square_close
    ',' â‰ª n && return n â‰› :comma
    ':' â‰ª n && return n â‰› :colon
    't' â‰ª n && return n â‹† Symbol("true") â‹† 4
    'f' â‰ª n && return n â‹† Symbol("false") â‹† 5
    'n' â‰ª n && return n â‹† :null â‹† 4
    '"' â‰ª n && return n â‹† :string â‹† â†’((Â¬('\\'), '"'))
    âˆˆ(b"-0123456789") â‰ª n && return n â‹† :number â‹† â‰º(âˆ‰(b"-+eE.0123456789"))
    âˆˆ(b" \t\n\r") â‰ª n && return n â‹† :whitespace â‹† â‰º(âˆ‰(b" \t\n\r"))
    return n â‰› :unknown
end

# # Array = "or"
# # Tuple = specific ordering
# # Symbol = rule
# json_grammar = (
#     json = [:element],
#     value = [:object, :array, :string, :number, "true", "false", "null"],
#     object = [('{', :members, '}'), ('{', :ws, '}')],
#     members = [:member, (:member, ',', :members)],
#     member = [(:ws, :string, :ws, ':', :element)],
#     array = [('[', :elements, ']'), ('[', :ws, ']')],
#     elements = [:element, (:element, ',', :elements)],
#     element = [(:ws, value :ws)],
#     string = [('"', :characters, '"')],
#     characters = ["", (:character, :characters)],
#     character = [SetDiff(' ':'\U10ffff', "\"\\"), ('\\', :escape)],
#     escape = ['"', '\\', '/', 'b', 'f', 'n', 'r', 't', ('u', :hex, :hex, :hex, :hex)],
#     hex = [:digit, 'A':'F', 'a':'f'],
#     number = [:integer :fraction :exponent],
#     integer = [:digit, (:onenine, :digits), ('-', :digit), ('-', :onenine, :digits)],
#     digits = [:digit, (:digit, :digits)],
#     digit = ['0', :onenine],
#     onenine = ['1':'9'],
#     fraction = ["", ('.', :digits)],
#     exponent = ["", ('E', :sign, :digits), ('e', :sign, :digits)],
#     sign = ["", '+', '-'],
#     ws = ["", (' ', :ws), ('\t', :ws), ('\n', :ws), ('\r', :ws)]
# )

#-----------------------------------------------------------------------------# HTMLTokens
struct HTMLTokens{T <: Data} <: Tokenizer{T, Symbol, @NamedTuple{style::Bool, script::Bool, tag::Bool}}
    data::T
end
function next(o::HTMLTokens, n)
    ğ‘ (isspace) â‰ª n && return n â‹† :whitespace â‹† â‰º(ğ‘ (!isspace))
    # state tag=true
    b"<script" â‰ª n && return n â‹† :open_tag_start â‹† â‰º(âˆˆ(b" >")) â‹† State(script=true, tag=true)
    b"<style" â‰ª n && return n â‹† :open_tag_start â‹† â‰º(âˆˆ(b" >")) â‹† State(script=true, tag=true)
    if n.state.tag
        âˆˆ(UInt8('a'):UInt8('z')) â‰ª n && return n â‹† :tag_name â‹† â‰º(âˆ‰(UInt8('a'):UInt8('z')))
        '=' â‰ª n && return n â‰› :equals
        '"' â‰ª n && return n â‹† :attr_val â‹† '"'
    end
    n.state.script && return n â‹† :text â‹† â‰º(â†(b"</script>")) â‹† State(script=false)
    n.state.style && return n â‹† :text â‹† â‰º(â†(b"</style>")) â‹† State(style=false)
    b"<!--" â‰ª n && return n â‹† :comment â‹† â†’(b"-->")
    b"<!" â‰ª n && return n â‹† :doctype_start â‹† 9 â‹† State(tag=true)
    b"</" â‰ª n && return n â‹† :close_tag_start â‹† '>'
    '>' â‰ª n && return (n â‰› :open_tag_end) â‹† State(tag=false)
    '<' â‰ª n && return n â‹† :open_tag_start â‹† â‰º(âˆˆ(b" >")) â‹† State(tag=true)
    return n â‹† :text â‹† â‰º('<')
end

#-----------------------------------------------------------------------------# XMLTokens
struct XMLTokens{T <: Data} <: Tokenizer{T, Symbol, Bool}
    data::T
end
function next(o::XMLTokens, n::Token)
    ğ‘ (isspace) â‰ª n && return n â‹† :whitespace â‹† â‰º(ğ‘ (!isspace))
    if n.state  # in_tag
        '=' â‰ª n && return n â‰› :equals
        '"' â‰ª n && return n â‹† :attr_val â‹† '"'
        '>' â‰ª n && return (n â‰› :open_tag_end) â‹† State(false)
        b"/>" â‰ª n && return n â‹† :self_close_tag_end â‹† 2 â‹† State(false)
        return n â‹† :attr_name â‹† â‰º(âˆˆ(b" ="))
    end
    b"<?" â‰ª n && return n â‹† :pi_start â‹† â‰º(âˆˆ(b" ")) â‹† State(true)
    b"?>" â‰ª n && return n â‹† :pi_end â‹† 2 â‹† State(false)
    b"<!--" â‰ª n && return n â‹† :comment â‹† â†’(b"-->")
    b"<![" â‰ª n && return n â‹† :cdata â‹† â†’(b"]]>")
    b"</" â‰ª n && return n â‹† :close_tag â‹† '>'
    '<' â‰ª n && return n â‹† :open_tag_start â‹† â‰º(âˆˆ(b" >")) â‹† State(true)
    return n â‹† :text â‹† â‰º('<')
end

#-----------------------------------------------------------------------------# Rule
# struct Rule{I, F, T, O}
#     in_state::I
#     from::F
#     to::T
#     out_state::O
# end

end  # module
